<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Clasificador de Flores â€“ TensorFlow.js</title>

  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"/>

  <style>
    body { background: #0f172a; color: #e5e7eb; }
    header { border-bottom: 1px solid #1f2937; }
    .brand-logo { width: 90px; height: 90px; object-fit: contain; }
    #canvas { max-width: 100%; border-radius: 12px; border: 1px solid #1f2937; }
    #resultado { font-weight: 800; font-size: clamp(2rem, 6vw, 3.5rem); text-align: center; margin-top: .5rem; }
    .badge-pulse { animation: pulse 1.5s infinite; }
    @keyframes pulse { 0% {opacity:.4} 50% {opacity:1} 100% {opacity:.4} }
    .prob-box { background:#0b1220; border:1px solid #1f2937; border-radius:12px; padding:12px; }
    .bar { height: 10px; border-radius: 999px; background:#111827; overflow:hidden }
    .bar > div { height:100%; width:0% }
  </style>
</head>

<body>

  <header class="py-3 text-center">
    <img src="img/flowers.png" alt="Logo" class="brand-logo mb-2" />
    <h1 class="fw-bold">Flower Classifier</h1>
    <p class="text-secondary">
      Real-time flower recognition using your phone camera and TensorFlow.js
    </p>

    <div class="d-flex justify-content-center">
      <span id="model-status" class="badge text-bg-warning badge-pulse">
        Loading modelâ€¦
      </span>
    </div>

    <small class="text-secondary">
      Requires <strong>HTTPS</strong> (or localhost) to access the camera.
    </small>
  </header>


  <main class="container py-4">
    <div class="row justify-content-center">
      <div class="col-12 col-md-6 text-center">

        <video id="video" playsinline autoplay muted style="display:none;"></video>

        <div class="d-grid gap-2 d-md-flex justify-content-md-center mb-3">
          <button class="btn btn-primary" onclick="iniciar()">Start Camera</button>
          <button class="btn btn-outline-light" onclick="cambiarCamara()">Switch Camera</button>
        </div>

        <canvas id="canvas" width="400" height="400"></canvas>

        <div id="resultado" class="mt-3">â€”</div>

        <div class="prob-box mt-3">
          <p class="text-start mb-1">Class probabilities</p>
          <div id="probs-container"></div>
        </div>
      </div>
    </div>
  </main>


  <footer class="py-4 text-center text-secondary">
    Built by <strong>Ana Laura Chenoweth Galaz</strong> â€” Using Transfer Learning + TF.js
  </footer>


  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

  <script>
    const tamano = 400;
    const inputSize = 224;
    const NUM_CLASSES = 104;
    const CLASS_NAMES = [...Array(NUM_CLASSES).keys()].map(i => "Class " + i);

    let modelo = null;
    let currentStream = null;
    let facingMode = "environment";


    // ========== Cargar modelo ==========
    async function cargarModelo() {
      try {
        const status = document.getElementById("model-status");
        status.textContent = "Loading modelâ€¦";

        modelo = await tf.loadLayersModel("web_model_flowers/model.json");

        // warmup
        tf.tidy(() => modelo.predict(tf.zeros([1, inputSize, inputSize, 3])));

        status.textContent = "Model ready âœ“";
        status.className = "badge text-bg-success";

      } catch (err) {
        alert("Error loading model: " + err.message);
        console.error(err);
      }
    }


    // ========== Iniciar cÃ¡mara ==========
    async function iniciar() {
      if (currentStream) currentStream.getTracks().forEach(t => t.stop());

      const constraints = {
        audio: false,
        video: { facingMode, width: tamano, height: tamano }
      };

      currentStream = await navigator.mediaDevices.getUserMedia(constraints);
      const video = document.getElementById("video");
      video.srcObject = currentStream;
      await video.play();

      loop();
    }


    // Cambiar cÃ¡mara
    async function cambiarCamara() {
      facingMode = (facingMode === "user") ? "environment" : "user";
      await iniciar();
    }


    // ========== Preprocesamiento ==========
    function getImageTensor() {
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d", { willReadFrequently: true });

      ctx.drawImage(video, 0, 0, tamano, tamano);

      return tf.tidy(() =>
        tf.browser.fromPixels(canvas)
          .resizeBilinear([inputSize, inputSize])
          .toFloat()
          .div(255.0)
          .reshape([1, inputSize, inputSize, 3])
      );
    }


    // ========== PredicciÃ³n ==========
    function actualizarProbs(pred) {
      const container = document.getElementById("probs-container");
      container.innerHTML = "";

      const values = pred.dataSync();

      // top 5
      const indices = [...values.keys()];
      indices.sort((a,b) => values[b] - values[a]);
      const top = indices.slice(0, 5);

      top.forEach(i => {
        const div = document.createElement("div");
        div.innerHTML = `
          <div class="d-flex justify-content-between">
            <span>${CLASS_NAMES[i]}</span>
            <span>${(values[i]*100).toFixed(1)}%</span>
          </div>
          <div class="bar mb-2"><div style="width:${values[i]*100}%; background:#3b82f6"></div></div>
        `;
        container.appendChild(div);
      });

      document.getElementById("resultado").textContent =
        CLASS_NAMES[top[0]] + " ðŸŒ¼";
    }


    // ========= Loop principal ==========
    async function loop() {
      const x = getImageTensor();
      const pred = modelo.predict(x);

      actualizarProbs(pred);

      x.dispose();
      if (pred.dispose) pred.dispose();

      requestAnimationFrame(loop);
    }


    // Inicializar
    window.addEventListener("load", cargarModelo);
  </script>
</body>
</html>
